* oltp vs olap
数据平台是由数据库组与数据分析组2部分组成的，oltp对应的就是生产环境下的交易数据库，而交易系统沉淀下来的数据，就>会源源不断的将数据同步到olap系统，做多维度的数据分析，产品运营。那么今天我们要分享的5种产品，主要就是基于olap的>，实现数据分析与计算，满足多场景产品介绍。
* 3个颜色
接下来，我们来看看数据流动图，我们来从总体上了解下5个产品处在什么位置，担任什么角色，在什么场景下给大家解决了什>么问题。
接下来我们大量的提到SQL，最后我会在总结的时候总结下到底什么是SQL？在OLAP系统中SQL与OLTP中有何不同.
好，
从颜色上来说，黄色代表了我们的产品，绿色代表了实时的数据流动，橙色相当于我们的批处理模型。
** 首先我们从黄色开始说起，我们的5个产品，对应了计算能力的输出与数据能力的输出
*** 计算型产品
实时计算，基于批计算实现的一致性对账和机器学习
我们在用机器学习和信息安全部共同实现基于流量的异常检测，现在批计算的数据分析结束，月底就会上实时的机器学习框架。
实时计算产品，大家一般都知道storm，spark streaming可以做，但是里面还是很复杂的，比如一致性问题，你是用日志时间处
理还是墙上时间处理，等等，这些你都需要考虑，我们在这些经验的基础上，封装了一层SQL的语义表达，也就是说，你想做实>时计算，一条sql下去就会生产一个topology计算拓扑或者说是spark的一个job，在生产为你执行，经过测试，我们是可以保证7*24小时高效稳定的,全公司的链路调度系统的实时计算就用于此产品。
基于批计算的一致性对账，基于spark的处理能力，我们实现了一致性对账v1.0的版本，支持A，B两个系统状态不一致的核对，>单边核对，也就是A有B无，A无B有的场景，在就是一对多的场景，以上的对账逻辑同样被我们抽象出来，你简单的配置下对账逻
辑，秒级处理百万条数据,产品中心部分子系统核对在使用比如，ncpay与银行子系统等，相信不久就会覆盖整个产品中心的对账
实现,未来我们还会开发2.0，进一步抽象逻辑，实现有级联关系的链式对账产品。
*** 接下来我们还看看数据型产品，主要面向技术，产品，运营等
ETL 异构数据源之间搞笑的数据加工整合聚合工具，这个工具是我们在比对了Sqoop，DataX等产品后，发现产品不是过重就是无
法满足我们的需求，因为这些产品都是缺少具体的数据处理逻辑的，在我们进一步调研这些产品的时候我们发现了其中的共性问
题，于是抽象出了现在的etl产品，数据处理的利器
NewReport，当ETL数据处理结束，到数据落地，我们需要多维度灵活的分，这个时候NewReport为大家提供了这样的便利，NewReport提供了多维度聚合数据的灵活查询，行列级别权限，支持数据钻取等等功能，稍后我的同事会做详细介绍。
在你用NewReport分析数据之后，恩，你可能需要给你的领导或同事，用更加直观的方式去展现你的数据，这个时候你就可以选>择我们的数据可视化产品Tableau，让你更加生动的去展现你的数据，让大家一目了然的做数据分析。
当然，还会存在一种情况，你希望自己做产品，做产品，更加定制化的分析你的数据，展现你的数据，这个时候DataAPI就可以>上场了，API的使用对象是其他的子系统，API提供了Restful的方式，对开发屏蔽掉了底层数据源的异构，无论你从DB2查数据，
MySQL查数据，HBase查数据，Phoenix查数据，或者查看通过实时计算落地的数据，你只需要一套Restful的DataAPI就可以了

这样，以上5种工具，针对不同的使用场景，提供了不同的产品，实现一套相对完整的数据闭环分析。
** 绿色，对应了实时计算的场景，比如说，全公司使用的链路调度系统，分析不同的机器上不同业务对应的不同接口的调用情>况，响应耗时，调用频率，性能分析，错误诊断等等场景，交易系统被请求，接受请求开始，调用若干子系统，比如订单系统调
交易系统，交易系统调路由，路由调银行子系统，等等，然后通过AOP的统一封装发送到kafka，然后做相应的数据清洗，然后进
入spark做实时计算，数据分析，然后数据落地，然后在通过DataAPI采集数据或者，同时取历史数据做比对，等等。
** 橙色，
当数据没有通过Kafka同步到HBase、HDFS的时候，我们会直接从备库中取数据，通过ETL做数据加工，统一建模，然后又NewReport，Tableau或者DataAPI做分析

