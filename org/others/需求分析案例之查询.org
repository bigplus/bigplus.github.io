#+TITLE: 需求分析之查询相关
#+AUTHOR: Jerry
#+OPTIONS: ^:nil

* 需求说明
*依据其他部门查询需求，我们将数据产品分为统计类查询和非统计类2种。（非统计类主要是基于维度查询）*
* 统计类查询需求分析

** 关于统计类查询特点分析
#+BEGIN_SRC 

统计类查询的特点是：基于终态数据的统计本身决定了对数据的实时计算（此类统计要区别于Storm实时计算）与信息获取实时性要求低，被视为离线数据分析的一种应用。
比如说，按小时，日，月等为基本统计单位,对于历史数据的统计,如基于一段时间交易笔数查询。
此时我们将HBase（持久化历史数据）视为一个巨大的Key-Value存储系统，为上层数据分析提供原数据，用于做离线的数据分析与报表生成。
#+END_SRC

** 统计类查询实现方式
*实现方式概要说明:*\\
+ *通过实现MapReduce程序或者写Hive SQL以及用Spark SQL来进行统计分析，以及计算.（稍后会简单的阐述MapReduce, Hive, Spark等使用场景）*\\
  PS : 通过Hadoop的分布式计算可以很好的避开传统数据库(db2/mysql)在处理海量的数据统计、分组、排序、过滤的操作对数据库性能的挑战.
  另外，由于hive为我们提供了熟悉的SQL操作接口，使我们像操作传统关系型数据库一样，很容易给出复杂查询、统计分析的SQL设计。
#+BEGIN_SRC 
  关于Mapreduce, Hive, Spark理解，以及大多数人的错误理解
  Mapreduce是 Google 03年发表的论文的apache版本实现，现在业界普遍认为它已经被淘汰并渐渐被spark取代。\\
  事实是，Spark是MR交互式查询能力不足的补充。而不是一种替代。
  spark作为一种内存计算模型，在内存中模拟了Mapreduce并扩展了功能，常常用于相对于MR小之的数据集用来建立分析原型，甚至是处理MapReduce的结果集用来建立分析原型。
  因此至少在先阶段，对于超大数据集我们依然会采用Mapreduce做基本的计算。
  Hive可以简单理解为Mapreduce的SQL封装。
  绝大多数需求可以通过hive完成，特殊复杂的考虑写Mapreduce。
#+END_SRC

+ *实现T-1的统计分析*
#+BEGIN_SRC 
第一点：
  首先我们考虑将计算得到的数据信息存入mysql。
  原因有2：
     (1) 统计后的信息较原始信息量级明显减小。
    （2）传统数据库的多维度查询优势方便业务开发。
#+END_SRC
+ 实现流程：
整体流程分简单，依据业务方数据量大小，选择处理处理方式，处理数据，写入mysql，对外暴露服务接口

    #+CAPTION: hbase2mysql总体流程
    [[./img/hbase2mysql.png]]

* 非统计类查询需求分析
** 基于HBase做非统计类查询的设计原则和实现方式

*非统计类查询即基于维度查询*\\
_PS:在此我们主要给出基于固定维度实时查询方案。_

#+BEGIN_SRC 
此类查询，使用HBase做数据库，设计原则为：抽象业务需求，建立领域对象表。
从2点说明为什么？
1. HBase本身一级索引决定的，我们简单的把HBase视为一个巨大的K/V数据库，Key即为一级索引。
我们不能随心所欲的构建二级索引，当然这么说部严谨，业界给出多种建立二级所以的方式，主要包括2类：
   a. 所以建立在hbase集群自身，最好的实现为华为给出的hindex，一种入侵式的实现
   b. 将索引建立在外部，比如建立在Elasticsearch中，当然这种网络开销比较大(不说了，这又能写一堆的字）
2. 如果每次对需求都建立一张HBase表，这样的开销是巨大的。
因此在业务层面必须合理抽象，依据数据仓库理念，合理构建数据仓库，才能合理的组建底层数据
#+END_SRC

比如：在线数据账户历史表根据业务规则把相关表（如商户信息，支付信息等）聚合到一起进行领域对象设计得到 ACCOUNT_HISTORY_TBL_DO. \\
从中我们可以得到此领域对象表的具体业务服务对象，依据服务对象建立HBase主键，然后通过程序做数据聚合，查询。\\
PS:最终得到一个领域表：所以相关查询都会落到这一张表上。\\
同时，配合HBase的查询特点，可以建立查询规则，过滤条件等，不是本文重点，不做过多阐述。
